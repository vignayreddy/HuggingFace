{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }},
    
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ],
      "metadata": {
        "id": "JdzD4TDSqJAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "logging.set_verbosity_error() is used beacuse it tells what model it have used by default i have removed it u can use it or give our own model so that no error was raised"
      ],
      "metadata": {
        "id": "4f0zNkye-vo2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB91r-fsnv2_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "TbbuQqYHobAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline,logging\n"
      ],
      "metadata": {
        "id": "mBVL2qLzo2lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "ans=generator(\"Lets learn something new\",max_length=30)\n",
        "logging.set_verbosity_error()\n",
        "ans[0][\"generated_text\"][:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s2XUb-v5-df6",
        "outputId": "7e7173bb-94b9-42db-f64e-4add880ad5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Lets learn something new about the game's mechanics.\\n\\nPlayers will take on the role of an ancient al\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "logging.set_verbosity_error()\n",
        "ans = classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaIWNPrmn_J-",
        "outputId": "8324d622-1662-416e-e458-8dbbb94ce595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "ans = classifier(\n",
        "    \"This is a course not  about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")\n",
        "logging.set_verbosity_error()\n",
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izgqTeLiq7O6",
        "outputId": "d20cee93-702d-404d-b0ff-fe4dfb31af14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course not  about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.5885071754455566, 0.32650691270828247, 0.08498593419790268]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmask = pipeline(\"fill-mask\")\n",
        "ans=unmask(\"You are a <mask> Person\",top_k=2)\n",
        "logging.set_verbosity_error()\n",
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUmfJ-gR-dtt",
        "outputId": "cdb30c9d-3cae-42cf-c8ed-4f144df2712d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.10682491213083267,\n",
              "  'token': 2822,\n",
              "  'token_str': ' Real',\n",
              "  'sequence': 'You are a Real Person'},\n",
              " {'score': 0.07431638240814209,\n",
              "  'token': 26411,\n",
              "  'token_str': ' Normal',\n",
              "  'sequence': 'You are a Normal Person'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named entity recognition (NER)\n",
        "\n",
        "\n",
        "```\n",
        "# PER(PERSON),ORG (ORGANIZATION),LOC (LOCATION) ,MISC (MISCELLANEOUS)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "5qL8xDDTDHfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WZiX2E2fEVn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\",grouped_entities=True)\n",
        "logging.set_verbosity_error()\n",
        "ans=ner(\"I am vignay reddy from Jagityal studying at CVR COLLEGE OF ENGINEERING\")\n",
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0nEeMbx-dvo",
        "outputId": "31b1047d-0077-48d9-967c-4feb6c5b419a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9267577),\n",
              "  'word': 'Jagityal',\n",
              "  'start': 23,\n",
              "  'end': 31},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.48203757),\n",
              "  'word': 'C',\n",
              "  'start': 44,\n",
              "  'end': 45},\n",
              " {'entity_group': 'MISC',\n",
              "  'score': np.float32(0.7350932),\n",
              "  'word': 'ENGINEERING',\n",
              "  'start': 59,\n",
              "  'end': 70}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qw = pipeline(\"question-answering\")\n",
        "ans= qw(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")\n",
        "logging.set_verbosity_error()\n",
        "ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX9Px1aI-d9x",
        "outputId": "c26ea9bb-455f-4f8c-b130-1897540aac08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.6949766278266907, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "ans=summarizer(\n",
        "    \"\"\"Nitish was bought by Sunrisers Hyderabad for Rs. 20 Lakh,\n",
        " in the 2023 Indian Premier League auction. He played just 2 matches in the league where he bowled a few overs but did not get to bat.[9] He had a breakout performance in the 2024 season,\n",
        "  where he won the Emerging Player of the Year Award by scoring 303 runs with strike rate of 142 with crucial knocks against Punjab Kings and Rajasthan Royals and also picked\n",
        "  up 3 wickets in the tournament showcasing\n",
        "   his immense talent and consistency throughout the tournament. He was subsequently retained by SRH in the 2025 IPL Auction for Rs. 6 Crores.\n",
        "   \"\"\")\n",
        "ans[0][\"summary_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfrz_6r-DvrB",
        "outputId": "954908c0-6efb-4007-f397-adde196fe0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Nitish was bought by Sunrisers Hyderabad for Rs. 20 Lakh in the 2023 Indian Premier League auction . He played just 2 matches in the league where he bowled a few overs but did not get to bat . He had a breakout performance in the 2024 season where he won the Emerging Player of the Year Award by scoring 303 runs with strike rate of 142 with crucial knocks against Punjab Kings and Rajasthan Royals .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " BERT stands for Bidirectional Encoder Representations from Transformers."
      ],
      "metadata": {
        "id": "9EDsL7iuLRal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pretraining is the act of training a model from scratch: the weights are randomly initialized, and the training starts without any prior knowledge."
      ],
      "metadata": {
        "id": "ZQYcpEA-MP2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens inside the pipeline function?"
      ],
      "metadata": {
        "id": "Hd4SuCxF3-Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "KYdY0F7fiYHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating ID'S"
      ],
      "metadata": {
        "id": "ZBnN2z_d6KWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "e99538a9f78a470ca72eadd351823fbe",
            "7a4fa24bf83d484e8de8b5de9a04659c",
            "6fbad02b9a2c4a14bae8aedaa7033ffb",
            "a3e804aea6ca4dc1b4a4d91c092f89e3",
            "b4e0b51d3e86434b81418d52f649542d",
            "2d88e3222c084d9fbe4b16257705fd5a",
            "78e514690999445392fcf74b439bacde",
            "516ac409f6d34d99b665af558ef4b6d4",
            "c846c3f8cd2a4335945c3dbc21a69175",
            "0f8a599638c34f9681f9dc35dd51290e",
            "2a46f75bb692440a83e582a7abb55cc5",
            "a225be0babcd41b48ab919a639e2b1f1",
            "f03d4859ae2748e499565df80c1bba01",
            "c2c2914407594b5ca208f1894ad9a994",
            "ea382172fb8749e78e7466348885c091",
            "d95183f4b56449b78dc96651f8f38628",
            "ee0f3b53498d4326a88be17ee7b99aa2",
            "793dd92dddec408da6f5f070e1a6bd0a",
            "c66209fc3d9a498798951b5cf013e1bc",
            "7668027ea37244eaa06ac0fffa7ee554",
            "f30ed622a02c468795fbd756c2debf3f",
            "1ce24e6043fe4ac7a398b13182798342",
            "e994f12b228346578b0eaf6af9e607c8",
            "1326d672435148389d19c2436848d58d",
            "cd435e47d9c74e4386a92aae99eb48d6",
            "18da3ce29a3643098d87359060fbe5c0",
            "c5472eabe3bf440b8ec494472dc050e6",
            "eeaff63c7f854de0b80d41eefd35a8b5",
            "8be1f10217984d67b101448c231366ba",
            "b7961c81064f430fad4797758ee7f74a",
            "7125149264604ac192492502df05cfd8",
            "4f45b1c14a25423eb92aa6c9832819e3",
            "8c1140ed18a34f96afc42c66fb3ba42d"
          ]
        },
        "id": "m7TY-MQK38Vr",
        "outputId": "01b413d6-726a-42e2-886b-da368164f9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e99538a9f78a470ca72eadd351823fbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a225be0babcd41b48ab919a639e2b1f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e994f12b228346578b0eaf6af9e607c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
              "          2607,  2026,  2878,  2166,  1012,   102],\n",
              "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModel.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "649b835a27d543a0abe36763483b2e4b",
            "38532d08d34b4d5fa7e1b777ff99694e",
            "54289e37307d4f139ea9761cca4edae7",
            "7d75ee2d73a84d47bb261ba41e90c17b",
            "1eb4a524d1bb44deabc50caa33f5ac25",
            "f742258ee280429fa248a4b59d7bc6e8",
            "04b26eca234b4d8eb6198cb0f2c9f6f1",
            "2eda9299250c4d47aa80f1cf4cde239b",
            "453bf8c3d6f54380a08bbdda0605dcc2",
            "8d1a4593fa634b1191f98565415bf62d",
            "19558d1776a540ffa2b6dc9780c3ea3b"
          ]
        },
        "id": "zAJI9B_v38Xk",
        "outputId": "5c9b35d2-a8bd-4eac-a0ba-d1a089c74640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "649b835a27d543a0abe36763483b2e4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logists are producd by AutoModelForXXX module"
      ],
      "metadata": {
        "id": "NF9mMwHx6BSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)\n",
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D316_6rX38Zc",
        "outputId": "b3eacb2a-eef6-456b-f7b4-17cda0fef190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "predictions = torch.nn.functional.softmax(outputs.logits,dim=1)\n",
        "print(predictions)\n",
        "model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwh_kGQD38dL",
        "outputId": "30eb528a-79ca-4638-a42a-a3fd137a7e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiating Transformer Models"
      ],
      "metadata": {
        "id": "sD42kCNc_L_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "bert_config = AutoConfig.from_pretrained(\"bert-base-cased\")\n",
        "print(type(bert_config))\n",
        "gpt_config = AutoConfig.from_pretrained(\"gpt2\")\n",
        "print(type(gpt_config))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e7f9f4a703744c348883b0bfa8dd1e83",
            "9dda2495b9094958be4bd05abbad6e28",
            "1584c80074e44429a6092035f87562cd",
            "96cc447b0a59430798651d540390856d",
            "db1230de0d384b83be7f47d88ba84b41",
            "82c57ee605c2403d895253ef9986e865",
            "1d09bb7b26a34b9891e53cd6d9aacb98",
            "6d87b1caf903415d8adcd0d1de7708c8",
            "0e000dad43a8477690f4ead87b557a3c",
            "ff9875329464480b81c52728c6240079",
            "d7b74ba4b0744bc8a584b1e53c4c4323"
          ]
        },
        "id": "7g-Ojty16is7",
        "outputId": "10c7d4fa-8e8a-408f-e921-f3157f4452e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7f9f4a703744c348883b0bfa8dd1e83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer"
      ],
      "metadata": {
        "id": "mImImwNlIEjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "sequence = \"Using a Transformer network is simple\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "print(tokens)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "decoded_string = tokenizer.decode([7993, 170, 13809, 23763, 2443, 1110, 3014])\n",
        "print(decoded_string)"
      ],
      "metadata": {
        "id": "T01JOBlY-7vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e3a664-5ceb-47f0-ba61-c4f64148ed3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n",
            "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n",
            "Using a Transformer network is simple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids = torch.tensor([ids])\n",
        "print(\"Input IDs:\", input_ids)\n",
        "output = model(input_ids)\n",
        "print(\"Logits:\", output.logits)\n",
        "val =tokenizer.decode(input_ids[0])\n",
        "print(val)"
      ],
      "metadata": {
        "id": "8XUDLHla_Qrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2aad94e-fffd-4ebc-a527-ebad97d4aa8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n",
            "i've been waiting for a huggingface course my whole life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two words/tokens are added. Lets see what it tells"
      ],
      "metadata": {
        "id": "YouHek_UM2aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(model_inputs[\"input_ids\"]))\n",
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI88B1AHJRhG",
        "outputId": "5e9ae6b2-93b8-4cf1-ad51-68c4c9d2f16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] i've been waiting for a huggingface course my whole life. [SEP]\n",
            "i've been waiting for a huggingface course my whole life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLS => Classification token\n",
        "SEP => Seperator to new line"
      ],
      "metadata": {
        "id": "WnRST7m6NM6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "model_inputs = tokenizer(sequence)\n",
        "print(model_inputs[\"input_ids\"])\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX-0UAAOJRdo",
        "outputId": "85277c51-c76b-46a7-94d2-0625be6f0509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]\n",
            "[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "output = model(**tokens)\n",
        "output.logits"
      ],
      "metadata": {
        "id": "Yw-3v0hm_Qxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d107a4fb-371e-4935-989e-0261bad683ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5607,  1.6123],\n",
              "        [-3.6183,  3.9137]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hugging Face DataSets Overview"
      ],
      "metadata": {
        "id": "9sXdXZWITR_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "#Downloads the MRPC dataset from the GLUE benchmark\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "id": "nhnvFMa2_Q1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691bdb48-b2c2-422d-df27-b0590497048a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3668\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 408\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}